{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGPDu29yhkgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "33e5ab77-11a4-48c3-c39b-2428a255b9bd"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57mFI240hpYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d326cab-d264-4f23-e4f2-eb324c488143"
      },
      "source": [
        "#word tokenize\n",
        "from nltk.tokenize import word_tokenize as wt\n",
        "text = \"This is Shubham's text. Shubham is a student of IIIT Bhopal. He is 20 year old.\"\n",
        "print(wt(text))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'Shubham', \"'s\", 'text', '.', 'Shubham', 'is', 'a', 'student', 'of', 'IIIT', 'Bhopal', '.', 'He', 'is', '20', 'year', 'old', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pOxHUvXhpkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b682ed96-1770-4622-8774-4087b43ce61b"
      },
      "source": [
        "# Tokenization of paragraphs/sentences\n",
        "import nltk\n",
        "\n",
        "\n",
        "paragraph = \"\"\"Independence Day is celebrated annually on 15 August as a national holiday in India commemorating the \n",
        "nation's independence from the United Kingdom on 15 August 1947, the day when the provisions of the Indian Independence\n",
        " Act 1947, which transferred legislative sovereignty to the Indian Constituent Assembly, came into effect. \n",
        " India retained King George VI as head of state until its transition to a full republic, when the nation adopted \n",
        " the Constitution of India on 26 January 1950 (celebrated as Indian Republic Day) and replaced the dominion prefix, \n",
        " Dominion of India, with the enactment of the sovereign law Constitution of India. India attained independence \n",
        " following the Independence Movement noted for largely non-violent resistance and civil disobedience.\"\"\"\n",
        "               \n",
        "# Tokenizing sentences\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "# Tokenizing words\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "print(sentences)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Independence Day is celebrated annually on 15 August as a national holiday in India commemorating the \\nnation's independence from the United Kingdom on 15 August 1947, the day when the provisions of the Indian Independence\\n Act 1947, which transferred legislative sovereignty to the Indian Constituent Assembly, came into effect.\", 'India retained King George VI as head of state until its transition to a full republic, when the nation adopted \\n the Constitution of India on 26 January 1950 (celebrated as Indian Republic Day) and replaced the dominion prefix, \\n Dominion of India, with the enactment of the sovereign law Constitution of India.', 'India attained independence \\n following the Independence Movement noted for largely non-violent resistance and civil disobedience.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk_vMcKbhpqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "95b21c9a-e4f6-4573-bd8e-dda4475dc590"
      },
      "source": [
        "#stop words\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w-WCe_Uhptm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cde4e41c-80eb-4b57-ab8a-f2caad604cd9"
      },
      "source": [
        "print(stopwords.words('english'))\n",
        "\n",
        "text = \"Ram's father is going to market.How are you?\"\n",
        "text_tokens = word_tokenize(text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "\n",
        "print(text_tokens)\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "['Ram', \"'s\", 'father', 'is', 'going', 'to', 'market.How', 'are', 'you', '?']\n",
            "['Ram', \"'s\", 'father', 'going', 'market.How', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJE80Wo9hpw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e9f1112-eb91-484a-bcf8-be9ed6360206"
      },
      "source": [
        "#stemming\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "porterStemmer = PorterStemmer()\n",
        "\n",
        "sentence=\"If, as an Indian, you feel very emotional and happy every 15th August, here is a list of other 5 nations whose citizens feel the same for their country too.\"\n",
        "wordList = nltk.word_tokenize(sentence)\n",
        "\n",
        "stemWords = [porterStemmer.stem(word) for word in wordList]\n",
        "\n",
        "print(' '.join(stemWords))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If , as an indian , you feel veri emot and happi everi 15th august , here is a list of other 5 nation whose citizen feel the same for their countri too .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8clmhFkiGwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "9c1df7bf-8e04-4775-d774-5892c21ac0a6"
      },
      "source": [
        "#word lemma\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"If, as an Indian, you feel very emotional and happy every 15th August, here is a list of other 5 nations whose citizens feel the same for their country too.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word                Lemma               \n",
            "If                  If                  \n",
            "as                  a                   \n",
            "an                  an                  \n",
            "Indian              Indian              \n",
            "you                 you                 \n",
            "feel                feel                \n",
            "very                very                \n",
            "emotional           emotional           \n",
            "and                 and                 \n",
            "happy               happy               \n",
            "every               every               \n",
            "15th                15th                \n",
            "August              August              \n",
            "here                here                \n",
            "is                  is                  \n",
            "a                   a                   \n",
            "list                list                \n",
            "of                  of                  \n",
            "other               other               \n",
            "5                   5                   \n",
            "nations             nation              \n",
            "whose               whose               \n",
            "citizens            citizen             \n",
            "feel                feel                \n",
            "the                 the                 \n",
            "same                same                \n",
            "for                 for                 \n",
            "their               their               \n",
            "country             country             \n",
            "too                 too                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zxyKe1ZiG0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "555ff709-3296-4e2c-f11b-9a50052e5806"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "txt = \"\"\"In India, 15th August is synonymous with the country's march into freedom when the British colonisers left the soil in 1947.\"\"\"\n",
        "[wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(txt))]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " 'India',\n",
              " ',',\n",
              " '15th',\n",
              " 'August',\n",
              " 'be',\n",
              " 'synonymous',\n",
              " 'with',\n",
              " 'the',\n",
              " 'country',\n",
              " \"'s\",\n",
              " 'march',\n",
              " 'into',\n",
              " 'freedom',\n",
              " 'when',\n",
              " 'the',\n",
              " 'British',\n",
              " 'coloniser',\n",
              " 'leave',\n",
              " 'the',\n",
              " 'soil',\n",
              " 'in',\n",
              " '1947',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2qaPAThnUlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c835d9a3-e543-49ab-a626-9ca58f1e9764"
      },
      "source": [
        "# TreebankWordTokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "text = \"This is Shubham's text. Shubham is a student of IIIT Bhopal. He is 20 year old.\"\n",
        "TreebankWordTokenizer().tokenize(text)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'Shubham',\n",
              " \"'s\",\n",
              " 'text.',\n",
              " 'Shubham',\n",
              " 'is',\n",
              " 'a',\n",
              " 'student',\n",
              " 'of',\n",
              " 'IIIT',\n",
              " 'Bhopal.',\n",
              " 'He',\n",
              " 'is',\n",
              " '20',\n",
              " 'year',\n",
              " 'old',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}